import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="1"
import time
import torch
import datetime

import torch.nn as nn
from torch.autograd import Variable
from torchvision.utils import save_image

from sagan_models import Generator, Discriminator
from utils import *
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from utils import make_folder
from sklearn.metrics import r2_score, mean_squared_error


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

class logcosh(nn.Module):
    """
    Log-Cosh æŸå¤±å‡½æ•°ã€‚
    å¯¹äºè¾ƒå°çš„è¯¯å·®ï¼Œå…¶è¡¨ç°ç±»ä¼¼äºå‡æ–¹è¯¯å·®(MSE)ï¼Œè€Œå¯¹äºè¾ƒå¤§çš„è¯¯å·®ï¼Œ
    å…¶è¡¨ç°ç±»ä¼¼äºå¯¹æ•°è¯¯å·®ï¼Œä½¿å…¶å¯¹å¼‚å¸¸å€¼ä¸é‚£ä¹ˆæ•æ„Ÿã€‚
    """
    def __init__(self):
        super().__init__()
        
    def forward(self, true, pred):
        loss = torch.log(torch.cosh(pred - true))
        return torch.sum(loss)


class LambdaLR():
    """
    ç”¨äºå­¦ä¹ ç‡è°ƒåº¦å™¨çš„è¾…åŠ©ç±»ï¼Œå®ç°çº¿æ€§è¡°å‡ã€‚
    """
    def __init__(self, n_epochs, offset, decay_start_epoch):
        assert ((n_epochs - decay_start_epoch) > 0), "è¡°å‡å¿…é¡»åœ¨è®­ç»ƒç»“æŸå‰å¼€å§‹!"
        self.n_epochs = n_epochs
        self.offset = offset
        self.decay_start_epoch = decay_start_epoch

    def step(self, epoch):
        # è®¡ç®—å­¦ä¹ ç‡çš„è¡°å‡å› å­
        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)

def weights_init_normal(m):
    """
    æƒé‡åˆå§‹åŒ–å‡½æ•°ã€‚
    """
    if isinstance(m, nn.Conv1d):
        torch.nn.init.xavier_uniform_(m.weight)
    elif isinstance(m, nn.InstanceNorm1d):
        pass
        
class Trainer(object):
    # æ­¥éª¤ 1: ä¿®æ”¹ __init__ æ–¹æ³•ä»¥æ¥æ”¶æ‰€æœ‰æ•°æ®åŠ è½½å™¨
    def __init__(self, data_loader, val_loader, test_loader, config):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨ã€‚
        
        å‚æ•°:
            data_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨ã€‚
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨ã€‚
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨ã€‚
            config: åŒ…å«æ‰€æœ‰è¶…å‚æ•°å’Œé…ç½®çš„å¯¹è±¡ã€‚
        """
        self.data_loader = data_loader
        self.val_loader = val_loader    # <-- æ¥æ”¶å¹¶ä¿å­˜éªŒè¯åŠ è½½å™¨
        self.test_loader = test_loader  # <-- æ¥æ”¶å¹¶ä¿å­˜æµ‹è¯•åŠ è½½å™¨

        # --- å…¶ä»–æ‰€æœ‰é…ç½®ä¿æŒä¸å˜ ---
        self.model = config.model
        self.adv_loss = config.adv_loss
        
        # æ¨¡å‹è¶…å‚æ•°
        self.imsize = config.imsize
        self.g_num = config.g_num
        self.z_dim = config.z_dim
        self.g_conv_dim = config.g_conv_dim
        self.d_conv_dim = config.d_conv_dim
        self.parallel = config.parallel

        self.lambda_gp = config.lambda_gp
        self.total_step = config.total_step
        self.d_iters = config.d_iters
        self.batch_size = config.batch_size
        self.num_workers = config.num_workers
        self.g_AECG_lr = config.g_AECG_lr
        self.g_MECG_lr = config.g_MECG_lr
        self.g_FECG_lr = config.g_FECG_lr
        self.g_BIAS_lr = config.g_BIAS_lr
        self.d_AECG_lr = config.d_AECG_lr
        self.d_MECG_lr = config.d_MECG_lr
        self.d_FECG_lr = config.d_FECG_lr
        self.d_BIAS_lr = config.d_BIAS_lr
        
        self.decay_start_epoch = 1  # å­¦ä¹ ç‡è¡°å‡å¼€å§‹çš„ epoch
        
        self.lr_decay = config.lr_decay
        self.beta1 = config.beta1
        self.beta2 = config.beta2
        self.pretrained_model = config.pretrained_model

        self.dataset = config.dataset
        self.use_tensorboard = config.use_tensorboard
        self.image_path = config.image_path
        self.log_path = config.log_path
        self.model_save_path = config.model_save_path
        self.sample_path = config.sample_path
        self.log_step = config.log_step
        self.sample_step = config.sample_step
        self.model_save_step = config.model_save_step
        self.version = config.version
        
        # åˆ›å»ºæ—¥å¿—ã€æ ·æœ¬å’Œæ¨¡å‹ä¿å­˜è·¯å¾„
        self.log_path_base = config.log_path
        self.sample_path_base = config.sample_path
        self.model_save_path_base = config.model_save_path
        self.version = config.version
        
        # æ­¥éª¤ 1: å…ˆè°ƒç”¨ make_folder åˆ›å»ºç›®å½•ï¼Œåˆ†åˆ«ä¼ å…¥åŸºç¡€è·¯å¾„å’Œç‰ˆæœ¬å·
        make_folder(self.log_path_base, self.version)
        make_folder(self.sample_path_base, self.version)
        make_folder(self.model_save_path_base, self.version)

        # æ­¥éª¤ 2: ç„¶åå†å®šä¹‰å®Œæ•´çš„è·¯å¾„å±æ€§ä¾›åç»­ä½¿ç”¨
        self.log_path = os.path.join(self.log_path_base, self.version)
        self.sample_path = os.path.join(self.sample_path_base, self.version)
        self.model_save_path = os.path.join(self.model_save_path_base, self.version)

        # æ„å»ºæ¨¡å‹
        self.build_model()
        
        if self.use_tensorboard:
            self.build_tensorboard()

        # å¦‚æœæŒ‡å®šï¼ŒåŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if self.pretrained_model:
            self.load_pretrained_model()

    # æ­¥éª¤ 2: å®Œæ•´é‡å†™ train æ–¹æ³•ï¼ŒåŠ å…¥éªŒè¯é€»è¾‘
    def train(self):
        """
        æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒå’ŒéªŒè¯æµç¨‹ã€‚
        """
        # ç¡®å®šèµ·å§‹ epoch
        if self.pretrained_model:
            start = self.pretrained_model + 1
        else:
            start = 0

        # åˆå§‹åŒ–è®¡æ—¶å™¨å’Œæœ€ä½³éªŒè¯æŸå¤±
        start_time = time.time()
        best_val_loss = float('inf') # ç”¨äºè®°å½•æœ€ä½³éªŒè¯æŸå¤±

        # å¤–å±‚å¾ªç¯ï¼Œä»£è¡¨è®­ç»ƒçš„æ€»è½®æ•° (Epochs)
        for epoch in range(start, self.total_step):
            # --- è®­ç»ƒé˜¶æ®µ ---
            self.model_train() # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼
            train_bar = tqdm(self.data_loader, desc=f'Epoch {epoch+1}/{self.total_step} [Training]')
            
            # å†…å±‚å¾ªç¯ï¼Œéå†ä¸€ä¸ª epoch çš„æ‰€æœ‰æ•°æ®æ‰¹æ¬¡
            for AECG_signals, FECG_signals, MECG_signals, BIAS_signals in train_bar: 
                # å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
                AECG_signals = AECG_signals.to(device)
                FECG_signals = FECG_signals.to(device)
                MECG_signals = MECG_signals.to(device)
                BIAS_signals = BIAS_signals.to(device)
                
                # å®šä¹‰çœŸå‡æ ‡ç­¾
                valid = torch.ones((AECG_signals.shape[0], 1, 128), dtype=torch.float32).to(device)
                fake = torch.zeros((AECG_signals.shape[0], 1, 128), dtype=torch.float32).to(device)
                
                # --- ç”Ÿæˆå™¨(G)è®­ç»ƒ ---
                self.optimizer_G_zero_grad()
                
                # === AECG <-> MECG ===
                # èº«ä»½æŸå¤±
                loss_generator_MECG = self.loss_generator(self.G_AECG2MECG(AECG_signals), MECG_signals.float()) * 1
                loss_generator_AECG_from_MECG = self.loss_generator(self.G_MECG2AECG(MECG_signals), AECG_signals.float()) * 1
                # GANæŸå¤±
                fake_MECG_signals = self.G_AECG2MECG(AECG_signals)
                loss_forwardGAN_AECG2MECG = self.loss_forwardGAN(self.D_AECG2MECG(fake_MECG_signals), valid)
                fake_AECG_signals_from_MECG = self.G_MECG2AECG(MECG_signals)
                loss_forwardGAN_MECG2AECG = self.loss_forwardGAN(self.D_MECG2AECG(fake_AECG_signals_from_MECG), valid)
                # å¾ªç¯ä¸€è‡´æ€§æŸå¤±
                loss_cycleGAN_AECG2MECG2AECG = self.loss_cycleGAN(self.G_MECG2AECG(fake_MECG_signals), AECG_signals.float()) * 0.04
                loss_cycleGAN_MECG2AECG2MECG = self.loss_cycleGAN(self.G_AECG2MECG(fake_AECG_signals_from_MECG), MECG_signals.float()) * 0.04
                # æ€»GæŸå¤± (MECG) å¹¶åå‘ä¼ æ’­
                loss_G_total_AECG2MECG = loss_generator_MECG + loss_generator_AECG_from_MECG + loss_forwardGAN_AECG2MECG + loss_forwardGAN_MECG2AECG + loss_cycleGAN_AECG2MECG2AECG + loss_cycleGAN_MECG2AECG2MECG
                loss_G_total_AECG2MECG.backward(retain_graph=True)

                # === AECG <-> FECG ===
                # èº«ä»½æŸå¤±
                loss_generator_FECG = self.loss_generator(self.G_AECG2FECG(AECG_signals), FECG_signals.float()) * 4 # è®°å½•è¿™ä¸ªæŸå¤±ç”¨äºåç»­æ¯”è¾ƒ
                loss_generator_AECG_from_FECG = self.loss_generator(self.G_FECG2AECG(FECG_signals), AECG_signals.float()) * 4
                # GANæŸå¤±
                fake_FECG_signals = self.G_AECG2FECG(AECG_signals)
                loss_forwardGAN_AECG2FECG = self.loss_forwardGAN(self.D_AECG2FECG(fake_FECG_signals), valid)
                fake_AECG_signals_from_FECG = self.G_FECG2AECG(FECG_signals)
                loss_forwardGAN_FECG2AECG = self.loss_forwardGAN(self.D_FECG2AECG(fake_AECG_signals_from_FECG), valid)
                # å¾ªç¯ä¸€è‡´æ€§æŸå¤±
                loss_cycleGAN_AECG2FECG2AECG = self.loss_cycleGAN(self.G_FECG2AECG(fake_FECG_signals), AECG_signals.float()) * 0.04
                loss_cycleGAN_FECG2AECG2FECG = self.loss_cycleGAN(self.G_AECG2FECG(fake_AECG_signals_from_FECG), FECG_signals.float()) * 0.04
                # æ€»GæŸå¤± (FECG) å¹¶åå‘ä¼ æ’­
                loss_G_total_AECG2FECG = loss_generator_FECG + loss_generator_AECG_from_FECG + loss_forwardGAN_AECG2FECG + loss_forwardGAN_FECG2AECG + loss_cycleGAN_AECG2FECG2AECG + loss_cycleGAN_FECG2AECG2FECG
                loss_G_total_AECG2FECG.backward(retain_graph=True)

                # === AECG <-> BIAS ===
                # èº«ä»½æŸå¤±
                loss_generator_BIAS = self.loss_generator(self.G_AECG2BIAS(AECG_signals), BIAS_signals.float()) * 1
                loss_generator_AECG_from_BIAS = self.loss_generator(self.G_BIAS2AECG(BIAS_signals), AECG_signals.float()) * 1
                # GANæŸå¤±
                fake_BIAS_signals = self.G_AECG2BIAS(AECG_signals)
                loss_forwardGAN_AECG2BIAS = self.loss_forwardGAN(self.D_AECG2BIAS(fake_BIAS_signals), valid)
                fake_AECG_signals_from_BIAS = self.G_BIAS2AECG(BIAS_signals)
                loss_forwardGAN_BIASAECG = self.loss_forwardGAN(self.D_BIAS2AECG(fake_AECG_signals_from_BIAS), valid)
                # å¾ªç¯ä¸€è‡´æ€§æŸå¤±
                loss_cycleGAN_AECG2BIAS2AECG = self.loss_cycleGAN(self.G_BIAS2AECG(fake_BIAS_signals), AECG_signals.float()) * 0.04
                loss_cycleGAN_BIAS2AECG2BIAS = self.loss_cycleGAN(self.G_AECG2BIAS(fake_AECG_signals_from_BIAS), BIAS_signals.float()) * 0.04
                # æ€»GæŸå¤± (BIAS) å¹¶åå‘ä¼ æ’­
                loss_G_total_AECG2BIAS = loss_generator_BIAS + loss_generator_AECG_from_BIAS + loss_forwardGAN_AECG2BIAS + loss_forwardGAN_BIASAECG + loss_cycleGAN_AECG2BIAS2AECG + loss_cycleGAN_BIAS2AECG2BIAS
                loss_G_total_AECG2BIAS.backward(retain_graph=True)
                
                # æ›´æ–°æ‰€æœ‰ç”Ÿæˆå™¨çš„æƒé‡
                self.optimizer_G_step()

                # --- åˆ¤åˆ«å™¨(D)è®­ç»ƒ ---
                self.optimizer_D_zero_grad()
                
                # === AECG <-> MECG ===
                loss_D_real_AECG2MECG = self.loss_forwardGAN(self.D_AECG2MECG(AECG_signals), valid)
                loss_D_fake_AECG2MECG = self.loss_forwardGAN(self.D_AECG2MECG(fake_AECG_signals_from_MECG.detach()), fake)
                loss_D_AECG2MECG = (loss_D_real_AECG2MECG + loss_D_fake_AECG2MECG) * 0.5
                loss_D_AECG2MECG.backward(retain_graph=True)

                loss_D_real_MECG2AECG = self.loss_forwardGAN(self.D_MECG2AECG(MECG_signals), valid)
                loss_D_fake_MECG2AECG = self.loss_forwardGAN(self.D_MECG2AECG(fake_MECG_signals.detach()), fake)
                loss_D_MECG2AECG = (loss_D_real_MECG2AECG + loss_D_fake_MECG2AECG) * 0.5
                loss_D_MECG2AECG.backward(retain_graph=True)

                # === AECG <-> FECG ===
                loss_D_real_AECG2FECG = self.loss_forwardGAN(self.D_AECG2FECG(AECG_signals), valid)
                loss_D_fake_AECG2FECG = self.loss_forwardGAN(self.D_AECG2FECG(fake_AECG_signals_from_FECG.detach()), fake)
                loss_D_AECG2FECG = (loss_D_real_AECG2FECG + loss_D_fake_AECG2FECG) * 0.5
                loss_D_AECG2FECG.backward(retain_graph=True)

                loss_D_real_FECG2AECG = self.loss_forwardGAN(self.D_FECG2AECG(FECG_signals), valid)
                loss_D_fake_FECG2AECG = self.loss_forwardGAN(self.D_FECG2AECG(fake_FECG_signals.detach()), fake)
                loss_D_FECG2AECG = (loss_D_real_FECG2AECG + loss_D_fake_FECG2AECG) * 0.5
                loss_D_FECG2AECG.backward(retain_graph=True)
                
                # === AECG <-> BIAS ===
                loss_D_real_AECG2BIAS = self.loss_forwardGAN(self.D_AECG2BIAS(AECG_signals), valid)
                loss_D_fake_AECG2BIAS = self.loss_forwardGAN(self.D_AECG2BIAS(fake_AECG_signals_from_BIAS.detach()), fake)
                loss_D_AECG2BIAS = (loss_D_real_AECG2BIAS + loss_D_fake_AECG2BIAS) * 0.5
                loss_D_AECG2BIAS.backward(retain_graph=True)

                loss_D_real_BIAS_AECG = self.loss_forwardGAN(self.D_BIAS2AECG(BIAS_signals), valid)
                loss_D_fake_BIAS2AECG = self.loss_forwardGAN(self.D_BIAS2AECG(fake_BIAS_signals.detach()), fake)
                loss_D_BIAS2AECG = (loss_D_real_BIAS_AECG + loss_D_fake_BIAS2AECG) * 0.5
                loss_D_BIAS2AECG.backward(retain_graph=True)

                # æ›´æ–°æ‰€æœ‰åˆ¤åˆ«å™¨çš„æƒé‡
                self.optimizer_D_step()

            # åœ¨æ¯ä¸ª epoch ç»“æŸåæ›´æ–°å­¦ä¹ ç‡
            self.optimizer_G_lr_step()
            self.optimizer_D_lr_step()
            train_bar.close()

            # --- éªŒè¯é˜¶æ®µ ---
            self.model_eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
            val_loss_total = 0.0
            val_batches = 0
            
            val_bar = tqdm(self.val_loader, desc=f'Epoch {epoch+1}/{self.total_step} [Validation]')
            with torch.no_grad(): # åœ¨éªŒè¯é˜¶æ®µä¸è®¡ç®—æ¢¯åº¦
                for AECG_signals, FECG_signals, _, _ in val_bar:
                    AECG_signals = AECG_signals.to(device)
                    FECG_signals = FECG_signals.to(device)
                    
                    # åªè®¡ç®—æˆ‘ä»¬æœ€å…³å¿ƒçš„ç”Ÿæˆå™¨æŸå¤±ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ (AECG -> FECG)
                    fake_FECG = self.G_AECG2FECG(AECG_signals)
                    val_loss = self.loss_generator(fake_FECG, FECG_signals.float())
                    
                    val_loss_total += val_loss.item()
                    val_batches += 1
            
            avg_val_loss = val_loss_total / val_batches if val_batches > 0 else 0
            
            # --- æ—¥å¿—è®°å½•å’Œæ¨¡å‹ä¿å­˜ ---
            elapsed = time.time() - start_time
            print(f"Epoch [{epoch+1}/{self.total_step}] | Elapsed: {str(datetime.timedelta(seconds=int(elapsed)))} | "
                  f"Train Loss (G_FECG): {loss_generator_FECG.item():.6f} | Validation Loss: {avg_val_loss:.6f}")

            # æ­¥éª¤ 3: ä¿®æ­£æ¨¡å‹ä¿å­˜é€»è¾‘
            # æ ¹æ®éªŒè¯æŸå¤±æ¥åˆ¤æ–­æ˜¯å¦ä¿å­˜æ¨¡å‹
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯æŸå¤±é™ä½è‡³ {best_val_loss:.6f}ã€‚æ­£åœ¨ä¿å­˜æ¨¡å‹...")
                # ä¿å­˜æ‰€æœ‰éœ€è¦çš„æ¨¡å‹ï¼Œä½¿ç”¨å›ºå®šçš„ "best" æ–‡ä»¶å
                torch.save(self.G_AECG2FECG.state_dict(), os.path.join(self.model_save_path, 'best_G_AECG2FECG.pth'))
                # æ‚¨ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œä¿å­˜å…¶ä»–æœ€å¥½çš„æ¨¡å‹
                torch.save(self.G_AECG2MECG.state_dict(), os.path.join(self.model_save_path, 'best_G_AECG2MECG.pth'))
                torch.save(self.G_AECG2BIAS.state_dict(), os.path.join(self.model_save_path, 'best_G_AECG2BIAS.pth'))
                # ... etc.

            # ä¿å­˜é‡‡æ ·å›¾ç‰‡ (é€»è¾‘ä¸å˜)
            if (epoch + 1) % self.sample_step == 0:
                # ä½¿ç”¨éªŒè¯é›†ä¸­çš„æœ€åä¸€ä¸ªæ‰¹æ¬¡æˆ–é‡æ–°åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡æ¥ç”Ÿæˆæ ·æœ¬
                fake_FECG_signals = self.G_AECG2FECG(AECG_signals)
                self.sample_images(epoch=epoch, batch_i=epoch, AECG=denorm(AECG_signals.cpu().detach().numpy()), FECG_reconstr=denorm(fake_FECG_signals.cpu().detach().numpy()),FECG=denorm(FECG_signals.cpu().detach().numpy()), sample_path=self.sample_path)


    def test(self):
        """
        åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶è®¡ç®— R^2 å’Œ RMSE æŒ‡æ ‡ã€‚
        """
        print("\n" + "="*40)
        print(" " * 12 + "è¿è¡Œæœ€ç»ˆæµ‹è¯•" + " " * 12)
        print("="*40)

        # æ­¥éª¤ 1: åŠ è½½è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„ã€è¡¨ç°æœ€å¥½çš„æ¨¡å‹æƒé‡
        best_model_path = os.path.join(self.model_save_path, 'best_G_AECG2FECG.pth')
        
        if not os.path.exists(best_model_path):
            print(f"é”™è¯¯: åœ¨ {best_model_path} æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹")
            print("è·³è¿‡æµ‹è¯•é˜¶æ®µã€‚")
            return

        print(f"ä»ä»¥ä¸‹è·¯å¾„åŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}")
        self.G_AECG2FECG.load_state_dict(torch.load(best_model_path))
        
        # æ­¥éª¤ 2: å°†æ‰€æœ‰æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.model_eval()
        
        # æ­¥éª¤ 3: å‡†å¤‡æ”¶é›†æ‰€æœ‰çœŸå®å€¼å’Œé¢„æµ‹å€¼
        all_ground_truths = []
        all_predictions = []
        
        # æ­¥éª¤ 4: éå†æµ‹è¯•æ•°æ®åŠ è½½å™¨
        with torch.no_grad():
            for aecg_signals, fecg_signals, _, _ in tqdm(self.test_loader, desc="Testing"):
                aecg_signals = aecg_signals.to(device)
                fecg_signals = fecg_signals.to(device) # çœŸå®ç›®æ ‡å€¼

                # é€šè¿‡ç”Ÿæˆå™¨è·å–é¢„æµ‹ä¿¡å·
                predicted_fecg_signals = self.G_AECG2FECG(aecg_signals)
                
                # æ”¶é›†çœŸå®å€¼å’Œé¢„æµ‹å€¼
                all_ground_truths.append(fecg_signals.cpu().numpy())
                all_predictions.append(predicted_fecg_signals.cpu().numpy())

        # æ­¥éª¤ 5: å°†æ‰€æœ‰æ‰¹æ¬¡çš„æ•°æ®åˆå¹¶æˆä¸€ä¸ªå¤§çš„Numpyæ•°ç»„
        all_ground_truths = np.concatenate(all_ground_truths, axis=0).reshape(-1, 1)
        all_predictions = np.concatenate(all_predictions, axis=0).reshape(-1, 1)
        
        print(f"æµ‹è¯•å®Œæˆã€‚åœ¨ {len(all_ground_truths)} ä¸ªæ•°æ®ç‚¹ä¸Šè®¡ç®—æŒ‡æ ‡ã€‚")

        # æ­¥éª¤ 6: è®¡ç®— RÂ² å’Œ RMSE
        r2 = r2_score(all_ground_truths, all_predictions)
        rmse = np.sqrt(mean_squared_error(all_ground_truths, all_predictions))
        
        # æ­¥éª¤ 7: æ‰“å°ç»“æœ
        print("\n--- æµ‹è¯•ç»“æœ ---")
        print(f"å†³å®šç³»æ•° (RÂ²) Score: {r2:.4f}")
        print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
        print("--------------------\n")

    def build_model(self):
        """
        æ„å»ºæ‰€æœ‰çš„ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œå¹¶å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ã€‚
        """
        # --- åˆ›å»ºç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ ---
        # AECG <-> MECG
        self.G_AECG2MECG = Generator(self.batch_size,self.imsize, self.z_dim, self.g_conv_dim).to(device)
        self.G_MECG2AECG = Generator(self.batch_size,self.imsize, self.z_dim, self.g_conv_dim).to(device)     
        self.D_AECG2MECG = Discriminator(self.batch_size,self.imsize, self.d_conv_dim).to(device)
        self.D_MECG2AECG = Discriminator(self.batch_size,self.imsize, self.d_conv_dim).to(device)
        
        # AECG <-> FECG
        self.G_AECG2FECG = Generator(self.batch_size,self.imsize, self.z_dim, self.g_conv_dim).to(device)
        self.G_FECG2AECG = Generator(self.batch_size,self.imsize, self.z_dim, self.g_conv_dim).to(device)
        self.D_AECG2FECG = Discriminator(self.batch_size,self.imsize, self.d_conv_dim).to(device)
        self.D_FECG2AECG = Discriminator(self.batch_size,self.imsize, self.d_conv_dim).to(device)
        
        # AECG <-> BIAS
        self.G_AECG2BIAS = Generator(self.batch_size,self.imsize, self.z_dim, self.g_conv_dim).to(device)
        self.G_BIAS2AECG = Generator(self.batch_size,self.imsize, self.z_dim, self.g_conv_dim).to(device)
        self.D_AECG2BIAS = Discriminator(self.batch_size,self.imsize, self.d_conv_dim).to(device)
        self.D_BIAS2AECG = Discriminator(self.batch_size,self.imsize, self.d_conv_dim).to(device)
        
        # --- å®šä¹‰æŸå¤±å‡½æ•° ---
        self.loss_generator = logcosh()      # ç”¨äºèº«ä»½æŸå¤±
        self.loss_forwardGAN = torch.nn.L1Loss() # ç”¨äºGANæŸå¤±
        self.loss_cycleGAN = logcosh()       # ç”¨äºå¾ªç¯ä¸€è‡´æ€§æŸå¤±
        
        # --- å®šä¹‰ä¼˜åŒ–å™¨ ---
        self.G_AECG2MECG_optimizer = torch.optim.Adam(self.G_AECG2MECG.parameters(), self.g_AECG_lr, [self.beta1, self.beta2])        
        self.G_MECG2AECG_optimizer = torch.optim.Adam(self.G_MECG2AECG.parameters(), self.g_MECG_lr, [self.beta1, self.beta2])
        self.D_AECG2MECG_optimizer = torch.optim.Adam(self.D_AECG2MECG.parameters(), self.d_AECG_lr, [self.beta1, self.beta2])
        self.D_MECG2AECG_optimizer = torch.optim.Adam(self.D_MECG2AECG.parameters(), self.d_MECG_lr, [self.beta1, self.beta2])
  
        self.G_AECG2FECG_optimizer = torch.optim.Adam(self.G_AECG2FECG.parameters(), self.g_AECG_lr, [self.beta1, self.beta2])        
        self.G_FECG2AECG_optimizer = torch.optim.Adam(self.G_FECG2AECG.parameters(), self.g_FECG_lr, [self.beta1, self.beta2])
        self.D_AECG2FECG_optimizer = torch.optim.Adam(self.D_AECG2FECG.parameters(), self.d_AECG_lr, [self.beta1, self.beta2])
        self.D_FECG2AECG_optimizer = torch.optim.Adam(self.D_FECG2AECG.parameters(), self.d_FECG_lr, [self.beta1, self.beta2])
    
        self.G_AECG2BIAS_optimizer = torch.optim.Adam(self.G_AECG2BIAS.parameters(), self.g_AECG_lr, [self.beta1, self.beta2])        
        self.G_BIAS2AECG_optimizer = torch.optim.Adam(self.G_BIAS2AECG.parameters(), self.g_BIAS_lr, [self.beta1, self.beta2])
        self.D_AECG2BIAS_optimizer = torch.optim.Adam(self.D_AECG2BIAS.parameters(), self.d_AECG_lr, [self.beta1, self.beta2])
        self.D_BIAS2AECG_optimizer = torch.optim.Adam(self.D_BIAS2AECG.parameters(), self.d_BIAS_lr, [self.beta1, self.beta2])

        # --- å®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨ ---
        self.G_AECG2MECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.G_AECG2MECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.G_MECG2AECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.G_MECG2AECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.D_AECG2MECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.D_AECG2MECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.D_MECG2AECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.D_MECG2AECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        
        self.G_AECG2FECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.G_AECG2FECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.G_FECG2AECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.G_FECG2AECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.D_AECG2FECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.D_AECG2FECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.D_FECG2AECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.D_FECG2AECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        
        self.G_AECG2BIAS_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.G_AECG2BIAS_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.G_BIAS2AECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.G_BIAS2AECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.D_AECG2BIAS_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.D_AECG2BIAS_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        self.D_BIAS2AECG_exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.D_BIAS2AECG_optimizer, lr_lambda=LambdaLR(self.total_step, 0, self.decay_start_epoch).step)
        
    def build_tensorboard(self):
        from logger import Logger
        self.logger = Logger(self.log_path)

    def load_pretrained_model(self):
        # æ³¨æ„ï¼šæ­¤å‡½æ•°å¯èƒ½éœ€è¦æ ¹æ®æ–°çš„ä¿å­˜é€»è¾‘è¿›è¡Œè°ƒæ•´
        # ç›®å‰ï¼Œå®ƒåŠ è½½çš„æ˜¯ä»¥ step å‘½åçš„æ—§æ¨¡å‹
        model_path = os.path.join(self.model_save_path, f'{self.pretrained_model}_G_AECG2FECG.pth')
        if os.path.exists(model_path):
             self.G_AECG2FECG.load_state_dict(torch.load(model_path))
             print(f'åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ (step: {self.pretrained_model})..!'.format(self.pretrained_model))
        else:
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°é¢„è®­ç»ƒæ¨¡å‹ {model_path}")

    # --- ä¼˜åŒ–å™¨è¾…åŠ©å‡½æ•° ---
    def optimizer_G_zero_grad(self):
        self.G_AECG2MECG_optimizer.zero_grad()
        self.G_MECG2AECG_optimizer.zero_grad()
        self.G_AECG2FECG_optimizer.zero_grad()
        self.G_FECG2AECG_optimizer.zero_grad()
        self.G_AECG2BIAS_optimizer.zero_grad()
        self.G_BIAS2AECG_optimizer.zero_grad()
        
    def optimizer_D_zero_grad(self):    
        self.D_AECG2MECG_optimizer.zero_grad()
        self.D_MECG2AECG_optimizer.zero_grad()
        self.D_AECG2FECG_optimizer.zero_grad()
        self.D_FECG2AECG_optimizer.zero_grad()
        self.D_AECG2BIAS_optimizer.zero_grad()
        self.D_BIAS2AECG_optimizer.zero_grad()
        
    def optimizer_G_step(self):
        self.G_AECG2MECG_optimizer.step()
        self.G_MECG2AECG_optimizer.step()
        self.G_AECG2FECG_optimizer.step()
        self.G_FECG2AECG_optimizer.step()
        self.G_AECG2BIAS_optimizer.step()
        self.G_BIAS2AECG_optimizer.step()
        
    def optimizer_D_step(self):    
        self.D_AECG2MECG_optimizer.step()
        self.D_MECG2AECG_optimizer.step()
        self.D_AECG2FECG_optimizer.step()
        self.D_FECG2AECG_optimizer.step()
        self.D_AECG2BIAS_optimizer.step()
        self.D_BIAS2AECG_optimizer.step()

    def optimizer_G_lr_step(self):     
        self.G_AECG2MECG_exp_lr_scheduler.step()
        self.G_MECG2AECG_exp_lr_scheduler.step()
        self.G_AECG2FECG_exp_lr_scheduler.step()
        self.G_FECG2AECG_exp_lr_scheduler.step()
        self.G_AECG2BIAS_exp_lr_scheduler.step()
        self.G_BIAS2AECG_exp_lr_scheduler.step()

    def optimizer_D_lr_step(self):
        self.D_AECG2MECG_exp_lr_scheduler.step()
        self.D_MECG2AECG_exp_lr_scheduler.step() 
        self.D_AECG2FECG_exp_lr_scheduler.step()
        self.D_FECG2AECG_exp_lr_scheduler.step()
        self.D_AECG2BIAS_exp_lr_scheduler.step()
        self.D_BIAS2AECG_exp_lr_scheduler.step()

    # --- æ¨¡å‹æ¨¡å¼åˆ‡æ¢è¾…åŠ©å‡½æ•° ---
    def model_train(self):
        """å°†æ‰€æœ‰æ¨¡å‹åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼"""
        self.G_AECG2MECG.train()
        self.G_MECG2AECG.train()    
        self.D_AECG2MECG.train()
        self.D_MECG2AECG.train()
        
        self.G_AECG2FECG.train()
        self.G_FECG2AECG.train()
        self.D_AECG2FECG.train()
        self.D_FECG2AECG.train()
    
        self.G_AECG2BIAS.train()
        self.G_BIAS2AECG.train()
        self.D_AECG2BIAS.train()
        self.D_BIAS2AECG.train()

    # æ­¥éª¤ 4: æ–°å¢ model_eval æ–¹æ³•
    def model_eval(self):
        """å°†æ‰€æœ‰æ¨¡å‹åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼"""
        self.G_AECG2MECG.eval()
        self.G_MECG2AECG.eval()    
        self.D_AECG2MECG.eval()
        self.D_MECG2AECG.eval()
        
        self.G_AECG2FECG.eval()
        self.G_FECG2AECG.eval()
        self.D_AECG2FECG.eval()
        self.D_FECG2AECG.eval()
    
        self.G_AECG2BIAS.eval()
        self.G_BIAS2AECG.eval()
        self.D_AECG2BIAS.eval()
        self.D_BIAS2AECG.eval()

    # --- æ ·æœ¬å¯è§†åŒ–å‡½æ•° ---
    def sample_images(self, epoch, batch_i, AECG, FECG_reconstr, FECG, sample_path):
        """
        ä¿å­˜ç”Ÿæˆçš„æ ·æœ¬å›¾åƒä»¥ä¾›å¯è§†åŒ–ã€‚
        """
        r, c = 1, 3
        # æ³¨æ„ï¼šåŸå§‹ä»£ç ä¸­ MECG æ ‡é¢˜å¯¹åº” AECG ä¿¡å·ï¼Œè¿™é‡Œä¿æŒä¸€è‡´
        gen_imgs = [AECG, FECG_reconstr, FECG]
        titles = ['AECG (Input)', 'Reconstructed FECG', 'Ground Truth FECG']
        
        fig, axs = plt.subplots(r, c, figsize=(18, 5))
        for j, (title, data) in enumerate(zip(titles, gen_imgs)):
            # ä»æ‰¹æ¬¡ä¸­é€‰æ‹©ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œç»˜åˆ¶
            sample_to_plot = data[0, 0, :]
            axs[j].plot(sample_to_plot)
            axs[j].set_title(title)
            axs[j].set_xlabel("Time Steps")
            axs[j].set_ylabel("Amplitude")
            axs[j].grid(True)
        
        fig.suptitle(f"Epoch {epoch+1}", fontsize=16)
        fig.tight_layout(rect=[0, 0.03, 1, 0.95])
        fig.savefig(os.path.join(sample_path, f"{epoch+1}_{batch_i}.png"), dpi=300)
        plt.close(fig)